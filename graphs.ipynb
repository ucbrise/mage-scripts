{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse output of end-to-end benchmarks\n",
    "class MageMeasurement(object):\n",
    "    def __init__(self, f):\n",
    "        lines = []\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            if len(tokens) >= 2 and tokens[1] == \"(ns)\":\n",
    "                stats = Stats(line)\n",
    "                if stats.name not in self.stats:\n",
    "                    self.stats[stats.name] = []\n",
    "                self.stats[stats.name].append(stats.total)\n",
    "            elif len(tokens) == 3 and tokens[0] == \"Timer:\" and tokens[2] == \"ns\":\n",
    "                self.time_for_computation_ns = int(tokens[1])\n",
    "                self.time_for_computation_ms = self.time_for_computation_ns / 1000000.0\n",
    "            lines.append(line)\n",
    "        if len(lines) == 0:\n",
    "            return\n",
    "        \n",
    "        tokens = lines[-1].split()\n",
    "        if len(tokens) == 2 and tokens[1] == \"ms\":\n",
    "            self.total_time_ms = int(tokens[0])\n",
    "        else:\n",
    "            assert(False)\n",
    "            self.total_time_ms = self.time_for_computation_ns / 1000000.0 # Hack to produce graphs with some missing data\n",
    "\n",
    "class EMPMeasurement(object):\n",
    "    def __init__(self, f):\n",
    "        lines = []\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "        assert(len(lines) == 4)\n",
    "        assert(lines[0] == \"connected\\n\")\n",
    "        assert(lines[2] == \"PASS\\n\")\n",
    "        self.time_for_computation_ms = int(lines[1].split()[1])\n",
    "        self.total_time_ms = int(lines[3].split()[1])\n",
    "        \n",
    "class PlanningMeasurement(object):\n",
    "    def __init__(self, f):\n",
    "        lines = []\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "        assert(len(lines) == 6)\n",
    "        phase_times = lines[5].split()\n",
    "        self.placement_ms = int(phase_times[3])\n",
    "        self.replacement_ms = int(phase_times[4])\n",
    "        self.scheduling_ms = int(phase_times[5])\n",
    "        self.total_ms = self.placement_ms + self.replacement_ms + self.scheduling_ms\n",
    "        \n",
    "class PlanStats(object):\n",
    "    def __init__(self, f):\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            tokens = line.split(\":\")\n",
    "            if len(tokens) == 2 and tokens[0] == \"Maximum resident set size (kbytes)\":\n",
    "                self.mem_usage_kb = int(tokens[1].strip())\n",
    "            elif len(tokens) == 6 and tokens[0] == \"Elapsed (wall clock) time (h\":\n",
    "                self.wall_clock_s = float(tokens[-1]) + (60 * int(tokens[-2]))\n",
    "            elif len(tokens) == 7 and tokens[0] == \"Elapsed (wall clock) time (h\":\n",
    "                self.wall_clock_s = float(tokens[-1]) + (60 * int(tokens[-2])) + (60 * 60 * int(tokens[-3]))\n",
    "                \n",
    "        \n",
    "class SEALMeasurement(object):\n",
    "    def __init__(self, f):\n",
    "        lines = []\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "        assert(len(lines) == 1)\n",
    "        self.total_time_ms = int(lines[0].split()[0])\n",
    "\n",
    "class Stats(object):\n",
    "    def __init__(self, line):\n",
    "        tokens = line.strip().split()\n",
    "        self.name = tokens[0]\n",
    "        self.unit = tokens[1][1:-2]\n",
    "        assert(tokens[3] == \"min\")\n",
    "        assert(tokens[6] == \"avg\")\n",
    "        assert(tokens[9] == \"max\")\n",
    "        assert(tokens[12] == \"count\")\n",
    "        assert(tokens[15] == \"sum\")\n",
    "        self.total = int(tokens[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename(prefix, program, scenario, tag):\n",
    "    if isinstance(tag, int):\n",
    "        tag = \"t{0}\".format(tag)\n",
    "    return \"{0}_{1}_{2}_{3}.log\".format(prefix, program, scenario, tag)\n",
    "\n",
    "def parse_emp_measurement_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return EMPMeasurement(f)\n",
    "\n",
    "def parse_mage_measurement_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return MageMeasurement(f)\n",
    "    \n",
    "def parse_seal_measurement_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return SEALMeasurement(f)\n",
    "    \n",
    "def parse_planning_measurement_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return PlanningMeasurement(f)\n",
    "    \n",
    "def parse_plan_stats_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return PlanStats(f)\n",
    "    \n",
    "def parse_plan_size_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return int(f.read().strip())\n",
    "\n",
    "    \n",
    "allowable_locations = (\"oregon\", \"iowa\", \"virginia\")\n",
    "\n",
    "def parse_log_directory(directory):\n",
    "    logs = {}\n",
    "    machine_directories = !ls {directory}\n",
    "    for mdir in machine_directories:\n",
    "        try:\n",
    "            machine_id = int(mdir)\n",
    "        except ValueError:\n",
    "            allowed = False\n",
    "            for loc in allowable_locations:\n",
    "                if mdir.startswith(loc):\n",
    "                    allowed = True\n",
    "                    break\n",
    "            if allowed:\n",
    "                machine_id = mdir\n",
    "            else:\n",
    "                print(\"Skipping directory {0}\".format(os.path.join(\"directory\", mdir)))\n",
    "                continue\n",
    "            \n",
    "        machine_logs = logs.setdefault(machine_id, {})\n",
    "            \n",
    "        log_files = !ls {os.path.join(directory, mdir)}\n",
    "        for log_file in log_files:\n",
    "            if log_file.endswith(\".log\") or log_file.endswith(\".planning\") or log_file.endswith(\".planstats\") or log_file.endswith(\".plansize\"):\n",
    "                log_path = os.path.join(directory, mdir, log_file)\n",
    "                \n",
    "                if os.stat(log_path).st_size == 0:\n",
    "                    print(\"Skpping empty file {0}\".format(log_path))\n",
    "                    continue\n",
    "                \n",
    "                parts = log_file.split(\".\")\n",
    "                extension = parts[-1]\n",
    "                name = \".\".join(parts[:-1])\n",
    "                \n",
    "                ext_logs = machine_logs.setdefault(extension, {})\n",
    "                \n",
    "                tokens = name.split(\"_\")\n",
    "                if len(tokens) < 6:\n",
    "                    print(\"Skipping(1) file {0}\".format(log_path))\n",
    "                    continue\n",
    "                if tokens[0] == \"wan\" or tokens[0] == \"pairedwan\":\n",
    "                    experiment = \"_\".join(tokens[:2])\n",
    "                    location = tokens[1]\n",
    "                    try:\n",
    "                        workers_per_node = int(tokens[2])\n",
    "                        ot_pipeline_depth = int(tokens[3])\n",
    "                        ot_num_daemons = int(tokens[4])\n",
    "                        size = int(tokens[-4])\n",
    "                    except ValueError as ve:\n",
    "                        print(ve)\n",
    "                        print(\"Skipping(2) file {0}\".format(log_path))\n",
    "                        continue\n",
    "                    problem = \"_\".join(tokens[5:-4])\n",
    "                    scenario = tokens[-3]\n",
    "                    tag = tokens[-2]\n",
    "                    worker = tokens[-1]\n",
    "                    experiments = ext_logs.setdefault(tokens[0], {}).setdefault(location, {}).setdefault(workers_per_node, {}).setdefault(problem, {}).setdefault(size, {}).setdefault(ot_pipeline_depth, {}).setdefault(ot_num_daemons, {}).setdefault(scenario, {}).setdefault(worker, {})\n",
    "                else:\n",
    "                    experiment = \"_\".join(tokens[:2])\n",
    "                    try:\n",
    "                        size = int(tokens[-3])\n",
    "                    except ValueError:\n",
    "                        print(\"Skipping file {0}\".format(log_path))\n",
    "                        continue\n",
    "                    problem = \"_\".join(tokens[2:-3])\n",
    "                    scenario = tokens[-2]\n",
    "                    tag = tokens[-1]\n",
    "                    experiments = ext_logs.setdefault(experiment, {}).setdefault(problem, {}).setdefault(size, {}).setdefault(scenario, {})\n",
    "                if tag in experiments:\n",
    "                    print(\"Skipping {0} (duplicate for {1})\".format(log_path, (experiment, problem, size, scenario, tag)))\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    if scenario in (\"os\", \"unbounded\", \"mage\"):\n",
    "                        if extension == \"log\":\n",
    "                            parsed = parse_mage_measurement_file(log_path)\n",
    "                        elif extension == \"planning\":\n",
    "                            parsed = parse_planning_measurement_file(log_path)\n",
    "                        elif extension == \"planstats\":\n",
    "                            parsed = parse_plan_stats_file(log_path)\n",
    "                        elif extension == \"plansize\":\n",
    "                            parsed = parse_plan_size_file(log_path)\n",
    "                    elif scenario == \"emp\":\n",
    "                        parsed = parse_emp_measurement_file(log_path)\n",
    "                    elif scenario == \"seal\":\n",
    "                        parsed = parse_seal_measurement_file(log_path)\n",
    "                    else:\n",
    "                        print(\"Skipping {0} (unknown scenario {1})\".format(log_path, scenario))\n",
    "                        continue\n",
    "                    experiments[tag] = parsed\n",
    "                except AssertionError as ae:\n",
    "                    print(\"Skipping {0} (assertion failure: {1})\".format(log_path, str(ae)))\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Simple, Guided Example\n",
    "======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_directory = \"logs-workloads-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_logs = parse_log_directory(simple_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data = simple_logs[0][\"log\"][\"workers_1\"][\"merge_sorted\"][1048576]\n",
    "\n",
    "simple_unbounded_time = simple_data[\"unbounded\"][\"t1\"].total_time_ms / 1000.0\n",
    "simple_mage_time = simple_data[\"mage\"][\"t1\"].total_time_ms / 1000.0\n",
    "simple_os_time = simple_data[\"os\"][\"t1\"].total_time_ms / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4, 3))\n",
    "\n",
    "labels = (\"Unbounded\", \"MAGE 1GiB\", \"OS 1 GiB\")\n",
    "values = (simple_unbounded_time, simple_mage_time, simple_os_time)\n",
    "\n",
    "plt.bar(labels, values)\n",
    "\n",
    "plt.ylabel(\"Time (s)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Experiments (Figures 6 and 7)\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_directory = \"logs-baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_logs = parse_log_directory(baseline_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_unbounded_style = {\"label\": \"Unbounded\", \"color\": \"blue\", \"marker\": \"s\", \"ls\": \"-\", \"linewidth\": 3}       \n",
    "baseline_mage_style = {\"label\": \"MAGE 1 GiB\", \"color\": \"orange\", \"marker\": \"^\", \"ls\": \"--\"}\n",
    "baseline_os_style = {\"label\": \"OS 1 GiB\", \"color\": \"green\", \"marker\": \"o\", \"ls\": \"-\"}\n",
    "baseline_emp_style = {\"label\": \"EMP 1 GiB\", \"color\": \"red\", \"marker\": \"v\", \"ls\": \"-.\"}\n",
    "baseline_seal_style = {\"label\": \"SEAL 1 GiB\", \"color\": \"red\", \"marker\": \"v\", \"ls\": \"-.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_halfgates_baseline_graph(sizes):\n",
    "    plt.figure(figsize = (3, 2))\n",
    "    \n",
    "    benchmark_data = baseline_logs[0][\"log\"][\"halfgates_baseline\"][\"merge_sorted\"]\n",
    "    def get_data(scenario, sizes, tag):\n",
    "        result = []\n",
    "        for size in sizes:\n",
    "            time_s = benchmark_data[size][scenario][tag].time_for_computation_ms / 1000.0\n",
    "            result.append(time_s)\n",
    "        return result\n",
    "\n",
    "    plt.plot(sizes, get_data(\"unbounded\", sizes, \"t1\"), **baseline_unbounded_style)\n",
    "    plt.plot(sizes, get_data(\"os\", sizes, \"t1\"), **baseline_os_style)\n",
    "    plt.plot(sizes, get_data(\"mage\", sizes, \"t1\"), **baseline_mage_style)\n",
    "    plt.plot(sizes, get_data(\"emp\", sizes, \"t1\"), **baseline_emp_style)\n",
    "\n",
    "    plt.xlim(0, sizes[-1])\n",
    "    \n",
    "    plt.xlabel(\"Problem Size (Records Per Party)\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    \n",
    "def draw_ckks_baseline_graph(sizes):\n",
    "    plt.figure(figsize = (3, 2))\n",
    "    \n",
    "    benchmark_data = baseline_logs[0][\"log\"][\"ckks_baseline\"][\"real_statistics\"]\n",
    "    def get_data(scenario, sizes, tag):\n",
    "        result = []\n",
    "        for size in sizes:\n",
    "            time_s = benchmark_data[size][scenario][tag].total_time_ms / 1000.0\n",
    "            result.append(time_s)\n",
    "        return result\n",
    "\n",
    "    plt.plot(sizes, get_data(\"unbounded\", sizes, \"t1\"), **baseline_unbounded_style)\n",
    "    plt.plot(sizes, get_data(\"os\", sizes, \"t1\"), **baseline_os_style)\n",
    "    plt.plot(sizes, get_data(\"mage\", sizes, \"t1\"), **baseline_mage_style)\n",
    "    plt.plot(sizes, get_data(\"seal\", sizes, \"t1\"), **baseline_seal_style)\n",
    "\n",
    "    plt.xlim(0, sizes[-1])\n",
    "    \n",
    "    plt.xlabel(\"Problem Size (Number of Elements)\")\n",
    "    plt.ylabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_halfgates_baseline_graph(tuple(2 ** i for i in range(13, 20)))\n",
    "plt.ylim(0, 200)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_halfgates_baseline_graph(tuple(2 ** i for i in range(13, 21)))\n",
    "plt.ylim(0, 1000)\n",
    "\n",
    "plt.xticks((0, 500000, 1000000))\n",
    "plt.ticklabel_format(style = \"plain\")\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_ckks_baseline_graph(tuple(2 ** i for i in range(8, 13)))\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_ckks_baseline_graph(tuple(2 ** i for i in range(8, 15)))\n",
    "plt.ylim(0, 250)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-Node Experiments\n",
    "====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_node_directory = \"logs-workloads-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_node_logs = parse_log_directory(single_node_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barwidth = 0.2\n",
    "errbarsize = 3\n",
    "styles = [{\"label\": \"Unbounded\", \\\n",
    "            \"width\": barwidth, \"capsize\": errbarsize, \"color\": \"blue\", \"hatch\": \"\", \"edgecolor\": \"black\"},          \n",
    "          {\"label\": \"MAGE 1 GiB\", \\\n",
    "           \"width\": barwidth, \"capsize\": errbarsize, \"color\": \"white\", \"hatch\": \"..\", \"edgecolor\": \"black\"},\n",
    "          {\"label\": \"OS 1 GiB\", \\\n",
    "           \"width\": barwidth, \"capsize\": errbarsize, \"color\": \"white\", \"hatch\": \"\\\\\\\\\", \"edgecolor\": \"black\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_round(value):\n",
    "    if value < 0.1:\n",
    "        return round(value, 3)\n",
    "    elif value < 1:\n",
    "        return round(value, 2)\n",
    "    elif value < 1000:\n",
    "        return round(value, 1)\n",
    "    else:\n",
    "        return int(round(value, 0))\n",
    "    \n",
    "def smart_round_percent(value):\n",
    "    if value < 0.1:\n",
    "        return round(value, 3)\n",
    "    elif value < 1:\n",
    "        return round(value, 2)\n",
    "    elif value < 10:\n",
    "        return round(value, 1)\n",
    "    else:\n",
    "        return int(round(value, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the \"autolabel\" function here: https://matplotlib.org/3.1.3/gallery/lines_bars_and_markers/barchart.html\n",
    "def autolabel(rects, errs, data, ove_imp = []):\n",
    "    for i, rect in enumerate(rects):\n",
    "        height = rect.get_height()\n",
    "        if ove_imp and False:\n",
    "            to_show = \"{0} ({1}%, {2}x)\".format(smart_round(data[i][2]), smart_round_percent((ove_imp[i][0] - 1) * 100), smart_round_percent(ove_imp[i][1]))\n",
    "        else:\n",
    "            to_show = \"{0}\".format(smart_round(data[i][2]))\n",
    "        plt.annotate(to_show,\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(-6, 3), # offset (to make room for error bar)\n",
    "                    textcoords = \"offset points\", rotation = 90,\n",
    "                    ha = \"center\", va = \"bottom\")\n",
    "        \n",
    "def draw_workloads_plot(experiments, graph_data, experiment_display_names, force_autolabel = False):\n",
    "    x = np.arange(0, len(experiments))\n",
    "    unbounded_err = [[(graph_data[e][\"unbounded\"][2] - graph_data[e][\"unbounded\"][1]) / graph_data[e][\"unbounded\"][2] for e in experiments], [(graph_data[e][\"unbounded\"][3] - graph_data[e][\"unbounded\"][2]) / graph_data[e][\"unbounded\"][2] for e in experiments]]\n",
    "    unbounded_bars = plt.bar(x - barwidth, [graph_data[e][\"unbounded\"][2] / graph_data[e][\"unbounded\"][2] for e in experiments], yerr = unbounded_err, **styles[0])\n",
    "    mage_err = [[(graph_data[e][\"mage\"][2] - graph_data[e][\"mage\"][1]) / graph_data[e][\"unbounded\"][2] for e in experiments], [(graph_data[e][\"mage\"][3] - graph_data[e][\"mage\"][2]) / graph_data[e][\"unbounded\"][2] for e in experiments]]\n",
    "    mage_bars = plt.bar(x, [graph_data[e][\"mage\"][2] / graph_data[e][\"unbounded\"][2] for e in experiments], yerr = mage_err, **styles[1])\n",
    "    os_err = [[(graph_data[e][\"os\"][2] - graph_data[e][\"os\"][1]) / graph_data[e][\"unbounded\"][2] for e in experiments], [(graph_data[e][\"os\"][3] - graph_data[e][\"os\"][2]) / graph_data[e][\"unbounded\"][2] for e in experiments]]\n",
    "    os_bars = plt.bar(x + barwidth, [graph_data[e][\"os\"][2] / graph_data[e][\"unbounded\"][2] for e in experiments], yerr = os_err, **styles[2])\n",
    "    \n",
    "    if force_autolabel:\n",
    "        autolabel(unbounded_bars, unbounded_err, [graph_data[e][\"unbounded\"] for e in experiments])\n",
    "        autolabel(mage_bars, mage_err, [graph_data[e][\"mage\"] for e in experiments], [(graph_data[e][\"mage\"][2] / graph_data[e][\"unbounded\"][2], graph_data[e][\"os\"][2] / graph_data[e][\"mage\"][2]) for e in experiments])\n",
    "        autolabel(os_bars, os_err, [graph_data[e][\"os\"] for e in experiments])\n",
    "    \n",
    "    plt.xticks(x, experiment_display_names)\n",
    "    plt.ylabel(\"Time (Normalized\\nby Unbounded)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_experiments = ((\"merge_sorted\", 1048576), (\"full_sort\", 1048576), (\"loop_join\", 2048), (\"matrix_vector_multiply\", 8192), (\"binary_fc_layer\", 16384))\n",
    "ckks_experiments = ((\"real_sum\", 65536), (\"real_statistics\", 16384), (\"real_matrix_vector_multiply\", 256), (\"real_naive_matrix_multiply\", 128), (\"real_tiled_16_matrix_multiply\", 128))\n",
    "\n",
    "experiments = hg_experiments + ckks_experiments\n",
    "experiment_display_names = (\"merge\\nn = 1048576\", \"sort\\nn = 1048576\", \"ljoin\\nn = 2048\", \"mvmul\\nn = 8192\", \"binfclayer\\nn = 16384\", \"rsum\\nn = 65536\", \"rstats\\nn = 16384\", \"rmvmul\\nn = 256\", \"n_rmatmul\\nn = 128\", \"t_rmatmul\\nn = 128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 2))\n",
    "\n",
    "num_machines = 1\n",
    "graph_data = {}\n",
    "for i, e in enumerate(experiments):\n",
    "    graph_data[e] = {}\n",
    "    print(experiment_display_names[i].split(\"\\n\")[0], end = \"\")\n",
    "    for scenario in (\"unbounded\", \"os\", \"mage\"):\n",
    "        total_times = []\n",
    "        for machine_id in range(num_machines):\n",
    "            benchmark_data = single_node_logs[machine_id][\"log\"][\"workers_1\"]\n",
    "            total_times.extend(m.total_time_ms / 1000.0 for tag, m in benchmark_data[e[0]][e[1]][scenario].items())\n",
    "        assert len(total_times) > 0\n",
    "        graph_data[e][scenario] = np.percentile(total_times, (0, 25, 50, 75, 100))\n",
    "        print(\" &\", round(np.median(total_times), 1), end=\"\")\n",
    "    print(\" &\", round(graph_data[e][\"os\"][2] / graph_data[e][\"mage\"][2], 1), end=\"\")\n",
    "    print(\" &\", round((graph_data[e][\"mage\"][2] / graph_data[e][\"unbounded\"][2] - 1) * 100, 0), end=\"\\\\%\")\n",
    "    print()\n",
    "\n",
    "draw_workloads_plot(experiments, graph_data, experiment_display_names)\n",
    "\n",
    "# Uncomment this line for the scale to match the one in the figure in the paper.\n",
    "plt.ylim(0, 15)\n",
    "# plt.xlim(-0.5, 10.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Support multiple trials done in parallel across different pairs of machines\n",
    "planning_data = single_node_logs[0][\"planning\"][\"workers_1\"]\n",
    "for i, e in enumerate(experiments):\n",
    "    graph_data[e] = {}\n",
    "    print(experiment_display_names[i].split(\"\\n\")[0], end = \"\")\n",
    "    planning_times = tuple(m.total_ms / 1000.0 for tag, m in planning_data[e[0]][e[1]][\"mage\"].items())\n",
    "    assert len(planning_times) > 0\n",
    "    graph_data[e][scenario] = np.percentile(planning_times, (0, 25, 50, 75, 100))\n",
    "    median = np.median(planning_times)\n",
    "    if median < 0.1:\n",
    "        rounded_median = round(median, 3)\n",
    "    elif median < 1:\n",
    "        rounded_median = round(median, 2)\n",
    "    else:\n",
    "        rounded_median = round(median, 1)\n",
    "    print(\" &\", rounded_median, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = 4 Parallelism Experiments\n",
    "========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_node_directory = \"logs-workloads-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_node_logs = parse_log_directory(multi_node_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_experiments_4 = ((\"merge_sorted\", 4194304), (\"full_sort\", 4194304), (\"loop_join\", 4096), (\"matrix_vector_multiply\", 16384), (\"binary_fc_layer\", 32768))\n",
    "ckks_experiments_4 = ((\"real_sum\", 262144), (\"real_statistics\", 65536), (\"real_matrix_vector_multiply\", 512), (\"real_naive_matrix_multiply\", 256), (\"real_tiled_16_matrix_multiply\", 256))\n",
    "\n",
    "experiments_4 = hg_experiments_4 + ckks_experiments_4\n",
    "experiment_4_display_names = (\"merge\\nn = 4194384\", \"sort\\nn = 4194384\", \"ljoin\\nn = 4096\", \"mvmul\\nn = 16384\", \"binfclayer\\nn = 32768\", \"rsum\\nn = 262144\", \"rstats\\nn = 32768\", \"rmvmul\\nn = 512\", \"n_rmatmul\\nn = 256\", \"t_rmatmul\\nn = 256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 2))\n",
    "\n",
    "# TODO: Support multiple trials done in parallel across different pairs of machines\n",
    "graph_data = {}\n",
    "for i, e in enumerate(experiments_4):\n",
    "    graph_data[e] = {}\n",
    "    print(experiment_4_display_names[i].split(\"\\n\")[0], end = \"\")\n",
    "    for scenario in (\"unbounded\", \"os\", \"mage\"):\n",
    "        instances_per_tag = {}\n",
    "        for machine in (0, 1, 2, 3):\n",
    "            machine_trials = multi_node_logs[machine][\"log\"][\"workers_4\"][e[0]][e[1]][scenario]\n",
    "            for tag, m in machine_trials.items():\n",
    "                instances_per_tag.setdefault(tag, []).append(m)\n",
    "                \n",
    "        total_times = []\n",
    "        for tag, machine_exps in instances_per_tag.items():\n",
    "            assert len(machine_exps) == 4\n",
    "            total_times.append(max(m.total_time_ms / 1000.0 for m in machine_exps))\n",
    "        assert len(total_times) > 0\n",
    "        graph_data[e][scenario] = np.percentile(total_times, (0, 25, 50, 75, 100))\n",
    "        print(\" &\", round(np.median(total_times), 1), end=\"\")\n",
    "    print(\" &\", round(graph_data[e][\"os\"][2] / graph_data[e][\"mage\"][2], 1), end=\"\")\n",
    "    print(\" &\", round((graph_data[e][\"mage\"][2] / graph_data[e][\"unbounded\"][2] - 1) * 100, 0), end=\"\\\\%\")\n",
    "    print()\n",
    "\n",
    "draw_workloads_plot(experiments_4, graph_data, experiment_4_display_names)\n",
    "\n",
    "# Uncomment this line for the scale to match the one in the figure in the paper.\n",
    "plt.ylim(0, 20)\n",
    "# plt.xlim(-0.5, 10.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAN Experiments: Number of Connections\n",
    "==================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wan_conn_directory = \"logs-wan-conn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wan_conn_logs = parse_log_directory(wan_conn_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wan_oregon_style = {\"label\": \"us-west1\", \"color\": \"blue\", \"ls\": \"-\"}\n",
    "wan_iowa_style = {\"label\": \"us-central1\", \"color\": \"orange\", \"ls\": \"-.\"}\n",
    "wan_virginia_style = {\"label\": \"us-east4\", \"color\": \"red\", \"ls\": \"-.\"}\n",
    "wan_lan_style = {\"label\": \"Local (US West 2)\", \"color\": \"green\", \"ls\": \"--\"}\n",
    "errbarsize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3, 2))\n",
    "\n",
    "num_workers = (1, 2, 4)\n",
    "exec_times_by_loc = {}\n",
    "for location in (\"oregon\", \"iowa\"):\n",
    "    if location == \"oregon\" or True:\n",
    "        ot_concurrency = 128\n",
    "        ot_num_connections = 1\n",
    "    elif location == \"iowa\":\n",
    "        ot_concurrency = 256\n",
    "        ot_num_connections = 1\n",
    "    exec_times = []\n",
    "    exec_times_by_loc[location] = exec_times\n",
    "    for num_workers_per_node in num_workers:\n",
    "        benchmark_data = wan_conn_logs[0][\"log\"][\"wan\"][location][num_workers_per_node][\"merge_sorted\"][1048576]\n",
    "        ot_pipeline_depth = ot_concurrency // (ot_num_connections * num_workers_per_node)\n",
    "        data = benchmark_data[ot_pipeline_depth][ot_num_connections][\"mage\"]\n",
    "\n",
    "        total_times = []\n",
    "        for tag in (\"t{0}\".format(i) for i in itertools.count(start = 1)):\n",
    "            if tag not in data[\"w0\"]:\n",
    "                break\n",
    "            measurements = []\n",
    "            for worker_id in (\"w{0}\".format(i) for i in range(num_workers_per_node)):\n",
    "                measurement = data[worker_id][tag]\n",
    "                measurements.append(measurement.total_time_ms / 1000.0)\n",
    "            total_times.append(np.max(measurements))\n",
    "        exec_times.append(np.percentile(total_times, (0, 25, 50, 75, 100)))\n",
    "\n",
    "error_bars = ([stats[2] - stats[1] for stats in exec_times_by_loc[\"oregon\"]], [stats[3] - stats[2] for stats in exec_times_by_loc[\"oregon\"]])\n",
    "plt.errorbar(num_workers, tuple(stats[2] for stats in exec_times_by_loc[\"oregon\"]), yerr = error_bars, capsize = errbarsize, **wan_oregon_style)\n",
    "error_bars = ([stats[2] - stats[1] for stats in exec_times_by_loc[\"iowa\"]], [stats[3] - stats[2] for stats in exec_times_by_loc[\"iowa\"]])\n",
    "plt.errorbar(num_workers, tuple(stats[2] for stats in exec_times_by_loc[\"iowa\"]), yerr = error_bars, capsize = errbarsize, **wan_iowa_style)\n",
    "\n",
    "plt.plot(num_workers, [174.5 for _ in num_workers], **wan_lan_style)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Number of workers\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "\n",
    "plt.ylim(0, 1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAN Experiments: OT Parallelism\n",
    "============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wan_ot_directory = \"logs-wan-ot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wan_ot_logs = parse_log_directory(wan_ot_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3, 2))\n",
    "    \n",
    "benchmark_data = wan_ot_logs[0][\"log\"][\"wan\"][\"oregon\"][1][\"merge_sorted\"][1048576]\n",
    "\n",
    "ot_concurrencies = (2, 4, 8, 16, 32, 64, 128, 256)\n",
    "exec_times = []\n",
    "for ot_concurrency in ot_concurrencies:\n",
    "    ot_num_connections = 2\n",
    "    ot_pipeline_depth = ot_concurrency // ot_num_connections\n",
    "    data = benchmark_data[ot_pipeline_depth][ot_num_connections][\"mage\"]\n",
    "    \n",
    "    total_times = []\n",
    "    for tag in (\"t{0}\".format(i) for i in itertools.count(start = 1)):\n",
    "        if tag not in data[\"w0\"]:\n",
    "            break\n",
    "        measurement = data[\"w0\"][tag]\n",
    "        total_times.append(measurement.total_time_ms / 1000.0)\n",
    "    exec_times.append(np.percentile(total_times, (0, 25, 50, 75, 100)))\n",
    "\n",
    "error_bars = ([stats[2] - stats[1] for stats in exec_times], [stats[3] - stats[2] for stats in exec_times])\n",
    "plt.errorbar(ot_concurrencies, tuple(stats[2] for stats in exec_times), yerr = error_bars, capsize = errbarsize, **wan_oregon_style)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"OT Concurrency\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 GiB Experiments\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_exp_directory = \"logs-16-16gb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_exp_logs = parse_log_directory(large_exp_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barwidth = 0.2\n",
    "errbarsize = 3\n",
    "styles = [{\"label\": \"Unbounded\", \\\n",
    "            \"width\": barwidth, \"capsize\": errbarsize, \"color\": \"blue\", \"hatch\": \"\", \"edgecolor\": \"black\"},          \n",
    "          {\"label\": \"MAGE 16 GiB\", \\\n",
    "           \"width\": barwidth, \"capsize\": errbarsize, \"color\": \"white\", \"hatch\": \"..\", \"edgecolor\": \"black\"},\n",
    "          {\"label\": \"OS 16 GiB\", \\\n",
    "           \"width\": barwidth, \"capsize\": errbarsize, \"color\": \"white\", \"hatch\": \"\\\\\\\\\", \"edgecolor\": \"black\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_experiments = ((\"merge_sorted\", 8388608), (\"full_sort\", 8388608), (\"loop_join\", 3840), (\"matrix_vector_multiply\", 20480), (\"binary_fc_layer\", 57344))\n",
    "ckks_experiments = ((\"real_sum\", 458752), (\"real_statistics\", 147456), (\"real_matrix_vector_multiply\", 448), (\"real_naive_matrix_multiply\", 256), (\"real_tiled_matrix_multiply\", 224))\n",
    "\n",
    "experiments = hg_experiments + ckks_experiments\n",
    "experiment_display_names = (\"merge\\nn = 8388608\", \"sort\\nn = 8388608\", \"ljoin\\nn = 3840\", \"mvmul\\nn = 20480\", \"binfclayer\\nn = 57344\", \"rsum\\nn = 458752\", \"rstats\\nn = 147456\", \"rmvmul\\nn = 448\", \"n_rmatmul\\nn = 256\", \"t_rmatmul\\nn = 224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 2))\n",
    "\n",
    "num_machines = 8\n",
    "graph_data = {}\n",
    "for i, e in enumerate(experiments):\n",
    "    graph_data[e] = {}\n",
    "    print(experiment_display_names[i].split(\"\\n\")[0], end = \"\")\n",
    "    for scenario in (\"unbounded\", \"os\", \"mage\"):\n",
    "        total_times = []\n",
    "        for machine_id in range(num_machines):\n",
    "            benchmark_data = large_exp_logs[machine_id][\"log\"][\"workers_1\"]\n",
    "            total_times.extend(m.total_time_ms / 1000.0 for tag, m in benchmark_data[e[0]][e[1]][scenario].items())\n",
    "        assert len(total_times) > 0\n",
    "        graph_data[e][scenario] = np.percentile(total_times, (0, 25, 50, 75, 100))\n",
    "        print(\" &\", round(np.median(total_times), 1), end=\"\")\n",
    "    print(\" &\", round(graph_data[e][\"os\"][2] / graph_data[e][\"mage\"][2], 1), end=\"\")\n",
    "    print(\" &\", round((graph_data[e][\"mage\"][2] / graph_data[e][\"unbounded\"][2] - 1) * 100, 0), end=\"\\\\%\")\n",
    "    print()\n",
    "\n",
    "draw_workloads_plot(experiments, graph_data, experiment_display_names)\n",
    "\n",
    "plt.ylim(0, 25)\n",
    "\n",
    "plt.legend(loc = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planning Data\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_planning = parse_log_directory(\"logs-workloads-2-planning\")\n",
    "large_planning = parse_log_directory(\"logs-16gib-workloads-2-planning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_names = (\"merge\", \"sort\", \"ljoin\", \"mvmul\", \"binfclayer\", \"rsum\", \"rstats\", \"rmvmul\", \"n_rmatmul\", \"t_rmatmul\")\n",
    "small_experiments = ((\"merge_sorted\", 1048576), (\"full_sort\", 1048576), (\"loop_join\", 2048), (\"matrix_vector_multiply\", 8192), (\"binary_fc_layer\", 16384), (\"real_sum\", 65536), (\"real_statistics\", 16384), (\"real_matrix_vector_multiply\", 256), (\"real_naive_matrix_multiply\", 128), (\"real_tiled_16_matrix_multiply\", 128))\n",
    "large_experiments = ((\"merge_sorted\", 8388608), (\"full_sort\", 8388608), (\"loop_join\", 3840), (\"matrix_vector_multiply\", 20480), (\"binary_fc_layer\", 57344), (\"real_sum\", 458752), (\"real_statistics\", 147456), (\"real_matrix_vector_multiply\", 448), (\"real_naive_matrix_multiply\", 256), (\"real_tiled_64_matrix_multiply\", 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_machines = 8\n",
    "for i, name in enumerate(generic_names):\n",
    "    small_list = []\n",
    "    large_list = []\n",
    "    for machine_id in range(num_machines):\n",
    "        e = small_experiments[i]\n",
    "        small = small_planning[machine_id][\"planstats\"][\"workers_1\"][e[0]][e[1]][\"mage\"][\"t1\"]\n",
    "        small_list.append(small)\n",
    "        \n",
    "        e = large_experiments[i]\n",
    "        large = large_planning[machine_id][\"planstats\"][\"workers_1\"][e[0]][e[1]][\"mage\"][\"t1\"]\n",
    "        large_list.append(large)\n",
    "        \n",
    "    small_time = np.median([m.wall_clock_s for m in small_list])\n",
    "    small_size = np.median([m.mem_usage_kb / 1024.0 for m in small_list])\n",
    "    large_time = np.median([m.wall_clock_s for m in large_list])\n",
    "    large_size = np.median([m.mem_usage_kb / 1024.0 for m in large_list])\n",
    "    print(\"{0} & {1} & {2} & {3} & {4}\".format(name, smart_round(small_time), smart_round(small_size), smart_round(large_time), smart_round(large_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Password Reuse Query\n",
    "==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_directory = \"logs-password-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_logs = parse_log_directory(password_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_unbounded_style = {\"label\": \"Unbounded\", \"color\": \"blue\", \"marker\": \"s\", \"ls\": \"-\", \"linewidth\": 3}       \n",
    "application_mage_style = {\"label\": \"MAGE with all available RAM\", \"color\": \"orange\", \"marker\": \"^\", \"ls\": \"--\"}\n",
    "application_os_style = {\"label\": \"OS with all available RAM\", \"color\": \"green\", \"marker\": \"o\", \"ls\": \"-\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_name = \"password\"\n",
    "mage_sizes = (1048576, 2097152, 4194304, 8388608, 16777216, 33554432, 67108864, 134217728)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 2))\n",
    "\n",
    "by_scenario = {}\n",
    "for scenario in (\"mage\", \"os\"):\n",
    "    by_size = {}\n",
    "    by_scenario[scenario] = by_size\n",
    "    for size in mage_sizes:\n",
    "        if size == mage_sizes[-1] and scenario == \"os\":\n",
    "            continue # We didn't collect this data point since it would take too long\n",
    "        by_trial = {}\n",
    "        by_size[size] = by_trial\n",
    "        for machine in (0, 1, 2, 3):\n",
    "            machine_trials = password_logs[machine][\"log\"][\"pairedwan\"][\"oregon\"][2][problem_name][size][64][1][scenario]\n",
    "            for worker, experiments in machine_trials.items():\n",
    "                for tag, m in experiments.items():\n",
    "                    by_trial.setdefault(tag, {})[worker] = m\n",
    "                    \n",
    "\n",
    "graph_data = {}\n",
    "for scenario in (\"mage\", \"os\"):\n",
    "    times = []\n",
    "    graph_data[scenario] = times\n",
    "    by_size = by_scenario[scenario]\n",
    "    for size in mage_sizes:\n",
    "        if size not in by_size:\n",
    "            print(\"No data for size {0} for scenario \\\"{1}\\\"\".format(size, scenario))\n",
    "            continue\n",
    "        size_data = by_size[size]\n",
    "        trial_measurements = []\n",
    "        for tag, worker_data in size_data.items():\n",
    "            worker_measurements = []\n",
    "            for worker, m in worker_data.items():\n",
    "                worker_measurements.append((m.total_time_ms / 1000.0) / 3600)\n",
    "            trial_measurements.append(np.max(worker_measurements))\n",
    "        print(trial_measurements)\n",
    "        times.append(np.median(trial_measurements))\n",
    "\n",
    "\n",
    "plt.xlabel(\"Number of Users/Passwords Per Party\")\n",
    "plt.ylabel(\"Execution Time (hours)\")\n",
    "\n",
    "plt.plot(mage_sizes, graph_data[\"mage\"], **application_mage_style)\n",
    "plt.plot(mage_sizes[:-1], graph_data[\"os\"], **application_os_style)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational PIR\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpir_directory = \"logs-cpir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpir_logs = parse_log_directory(cpir_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpir_name = \"real_cpir\"\n",
    "cpir_sizes = (256, 384, 512, 640, 768, 896, 1024, 1158, 1280, 1408, 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = {}\n",
    "for scenario in (\"mage\", \"os\"):\n",
    "    times = []\n",
    "    graph_data[scenario] = times\n",
    "    for size in cpir_sizes:\n",
    "        trials = []\n",
    "        for machine_id in range(4):\n",
    "            data = cpir_logs[machine_id][\"log\"][\"workers_1\"][cpir_name][size][scenario]\n",
    "            for tag, measurement in data.items():\n",
    "                trials.append((measurement.time_for_computation_ms / 1000.0) / 60.0)\n",
    "        times.append(np.median(trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 2))\n",
    "\n",
    "plt.plot(tuple(n * n for n in cpir_sizes), graph_data[\"mage\"], **application_mage_style)\n",
    "plt.plot(tuple(n * n for n in cpir_sizes), graph_data[\"os\"], **application_os_style)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(0, 80)\n",
    "\n",
    "plt.xlabel(\"Number of Batches (4096 Real Numbers Per Batch)\")\n",
    "plt.ylabel(\"Exec. Time (minutes)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
